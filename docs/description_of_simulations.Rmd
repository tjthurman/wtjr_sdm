---
title: "Simulation description"
output:
  rmdformats::readthedown:
    highlight: tango
    code_folding: hide
    toc_depth: 4
    theme: yeti
editor_options: 
  chunk_output_type: console
---

```{r setup, message=FALSE, warning=FALSE, echo = F}

# Load packages -----------------------------------------------------------
library(tidyverse)
library(cowplot)
library(ggrepel)
library(lemon)
library(knitr)
library(rmdformats)
library(broom)

# Set global options ------------------------------------------------------

## Global options
options(max.print="100", scipen = 1, digits = 2)
opts_chunk$set(cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.align = "center")
#opts_knit$set(width=75)
```


An explanation/description of the simulations I'm doing for the WTJR project. This document has been evolving as I set the simulation up, test things, and make changes. So it may be a little disjointed, but hopefully it makes sense. 

This document also goes into a lot of detail (maybe too much?). But one I suppose nice thing about doing simulations in a program like SLiM is you have to specify basically everything, so you have to think at least semi-deeply about everything. One thing I try to do throughout the document is make explicit some of the assumptions that are implicit in the way I set up the simulation. 

## Simulation program

I'm doing these simulations in SLiM. Right now while prototyping, I'm doing everything locally on my computer in SLiMgui v3.6. Once all the kinks are worked out locally and we're ready to run the simulations for real (varying parameters, doing lots of replicates), I'll run them on the cluster.

## General simulation format

SLiM does forward-in-time, individual-based simulations. Going down the hierarchy, within each simulation we have:

* Subpopulations- I'm simulating one subpopulation, so one panmictic population.
* Individuals: Each individual belongs to a subpopulation, and has multiple attributes. For our purposes, we care about each individual's genotype, and how that translates to their phenotpe and fitness.
* Genomes: Each individual is diploid, and thus has two copies of the genome.
* Genotypes: Within each genome, we track the frequencies of all variants in the genome. 

Importantly, SLiM can do simulations under two different population genetic models. The first is the Wright-Fisher model: effective population sizes are specified, generations are discrete and non-overlapping, and fitness/selection are related to mating success, not viability/survival, such that selection is soft. This is inappropriate for our question: we're explicitly interested in population declines, so we don't want the population size to be a specified constant: we want population size to be an emergent property of the fitness of the individuals in the population. So, I'm using the non-WF model: population regulation is specified (i.e., carrying capacity or density dependence), but population size is emergent. Generations can be overlapping, fitness/selection are related to survival/viability (such that individuals could survive for multiple generations), and selection is hard. 

It is helpful to briefly mention the generation cycle of the simulation. In the first step, the surviving "adults" from the previous generation make offspring. Then, individual fitnesses are calculated. In the nonWF model, these fitnesses are basically the probability of survival to the next generation, and range between 0 (will definitely die) and 1 (will definitely live). Fitness calculation happens in two steps in the model as I've specified it. First, every individual gets an initial survival probability based on their phenotype and the optimal phenotype for the environment. Then, those individual-level survival probabilities are rescaled according to some population-level regulation (basically, enforcing a carrying capacity). After fitness calculation, there is a period of viability selection: individuals live or die based on their survival probability. After that, the generation counter increments, the ages of the surviving individuals are increased by 1, and the process starts over. 

This non-WF model is appropriate, but we need to keep an eye on some of the emergent properties (population size, age structure, lifespan) to make sure they make sense for WTJR. Now, let's dive into the nitty-gritty aspects of the simulation.

### Mating and offspring generation

Currently, I am not modeling separate sexes, such that each diploid individual can be thought of as a hermaphrodite. In each generation, all living individuals are randomly paired up (with an odd # of individuals, 1 individual remains unpaired and doesn't mate). So, with 5000 individuals, we create 2500 random mating pairs. Within each mating, the usual rules of Mendelian genetics apply. 

I tried to find some estimates of reproductive output for WTJR. Number of litters per year can apparently vary from 1-4, and offspring per litter can also vary, but that has been harder to pin down: I'm seeing from 1 to 11 per litter. For now, each mating pair is randomly assigned a number of litters (weighted toward 1 or 2, but 3 to 4 litters are possible), and each litter can have between 1 and 4 offspring (equally weighted). Originally, I allowed between 1 and 6 offspring per litter. This turned out to be too high: as I discuss more below, if reproductive output is too high, populations can't go extinct even when they're completely mismatched. So this choice is somewhat of a practical one. I may re-do the way offspring are done (e.g., just drawing total offspring number for a mating pair from a Poisson distribution, instead of the litter/litter size thing). But, however it is modeled, the average number of offspring per pair ends up being an important parameter, and can't go too high if we want populations to be able to go extinct. 

This mating system has some implicit assumptions: pairing off all individuals is sort of an implicit 50/50 sex ratio (seems to agree with sex ratios in the wild, from what I can see in the literature). In this scheme, individuals are monogamous: one "male" is the father for all of a "female's" litters. Pairings are random, such that there is no mate choice or competition. I expect this is not true in the wild (we certainly know there is mate competition in the wild). That said, I'm not sure that changing those things would matter too much. Even if we stop monogamy, I'd say the most principled thing would still be to have females choose mates randomly (we have nothing besides winter phenotype for them to base their choice on, which shouldn't be relevant for mate choice). Really, I think the main thing to care about for the mating section is not mating dynamics, but offspring number. 

### Genome and molecular evolution

We're lucky for these simulations, in that we aren't interested in simulating a lot of the things people are usually interested in when using SLiM (e.g., simulating patterns of neutral genetic diversity across the genome). We're really just interested in two loci (for now): corin and EDNRB. So, I'm simulating very simple genomes. I could just simulate two loci, but to make visualization a little easier I'm technically simulating a single chromosome that is 300 bp long. We're only interested in relatively short-term evolution from standing genetic variation, so I set the mutation rate to 0, such that there are no neutral variants to track. We're only tracking alleles at two sites: at 100bp there is a single locus that represents corin, and at 200 bp there is a single locus that represents EDNRB. Across the genome, the recombination rate is 0, except between positions 149 and 150, where the recombination rate is 0.5. This makes our corin and EDNRB loci unlinked, as if they are on separate chromosomes, even though we're technically modeling one "chromosome". 

At the start of the simulation, I introduce mutations at the corin and EDNRB sites which represent winter-brown alleles. I specify the starting frequency for each gene, and the brown alleles are randomly assigned to whatever number of diploid genomes (not individuals) are necessary to achieve the desired starting frequency. I need to double check this, but this should mean that the alleles for each gene are in HW equilibrium at the start. Currently, these alleles are assigned independently for corin and EDNRB, such that these should, on average, be in linkage equilibrium at the start of the simulation. After this initial SGV is seeded, there is no further mutation at these genes, such that no additional brown alleles are introduced to the population (no gene flow or mutation). These brown mutations have no direct fitness effect, they simply influence the phenotype of the organism. All fitness calculations are based on these phenotypes. 

### Genotype-phenotype

So, how do we translate the genotypes at these two loci into a phenotype? For now, I'm using simple linear models that are similar to those presented in Table S11 of the supplemental material. These models relate an individual's phenotypic PC1 score to their genotypes at corin and EDNRB.  However, I had Mafalda make some changes for me, to make the modeling a little more intuitive. In the models in table S11, the phenotypic PC score is the same as shown in Figure 2: lower PC scores are more brown, and higher PC scores are more white. Similarly, the genotypes in the original model are coded as the number of winter-white alleles, such that adding more alleles increases the PC score (makes an individual more white).

To be more intuitive to our story, I wanted everything to be in terms of the brown allele, and I wanted the PC score scale to be flipped, such that higher PC scores mean more brown. So, Mafalda multiplied the PC score by -1 to flip the scale (now higher PC score = more brown), and re-ran the models in terms of number of brown alleles, instead of # of white alleles. Also, she dropped agouti for now, to keep it as the current 2-locus model. Here is the model table from that updated linear model (compare to model B in Table S11):

```{r}
load("tmp_models_from_mafalda/genotype_analyses_041021.RData")

tidy(fitD)
```

LTW_2_36361155 is the SNP representing corin, and LTW_8_79701598 represents EDNRB. From this linear model, then, we can get a sort of breeding value of each individual's PC1 phenotype, $y^{PC}$, based on the genotypes $x^{corin}$ and $x^{ednrb}$, where the intercepts and coeffiecients are just straight out of the model:

$y_{i}^{PC} = -6.48 + 1.92x^{corin}_{i} + 3.15x^{ednrb}_{i}$

It is important to note here that this linear model somewhat bounds the possible PC1 phenotypes: the minimum PC1 score (with no brown alleles) is -6.48, and the maximum PC1 score (homozygote brown at both alleles) is 3.66. These are less extreme than the min and max PC1 scores present in the dataset as a whole (basically to -10 and 10), but this is because the linear model doesn't use all phenotype data, but only phenotype data from individuals that we did the SNP genotyping for. 

In any case, this linear model gives us breeding values for each individual, and the variance in $y^{PC}$ gives us $V_{a}$, the additive genetic variance in the phenotype. We know the phenotype isn't 100% determined by these two alleles, so we can add in some phenotypic variance that is unexplained by these genotypes. The adjusted R-squared/PVE from this model is 64%, which we can more or less take as the heritability. So, we need $\frac{V_{A}}{V_{P}} \approx 0.64$. Since $V_{P} = V_{A} + V_{E}$:

$V_E=(V_A-h^2*V_A)/h^2$

From that equation, we figure out what $V_{E}$ we need to get our target heritability, and we add that variance in by adding a little noise to each individual phenotype, where the noise is drawn from a normal distribution with mean 0 and standard deviation equal to $\sqrt{V_{E}}$:

$\hat y_{i}^{PC} = y_{i}^{PC} + N(0, \sqrt{V_{E}})$

Then, our realized heritability is:

$\frac{Var(y_{i}^{PC})}{Var(\hat y_{i}^{PC})}$


The issue of heritability is tricky: as allele frequencies change, the $V_{A}$ will change (being highest at intermediate frequencies of both alleles). We can deal with this in two ways. One, we can hold heritability constant: each generation we can calculate anew what $V_{E}$ is needed to hit our target heritability, and we can add that. This is common in quantitative genetic models, but is maybe not realistic for our genetic architecture. The second is to calculate whatever $V_{E}$ we need in our first generation to have our initial heritability match our model, and then hold $V_{E}$ constant through the rest of the generations (this is what the recent Kardos and Luikart paper does). In this scenario, heritability will change from generation to generation as allele frequencies change. In this case, the initial conditions matter a lot, as the allele frequencies have a big effect on the initial $V_{E}$ (this initial effect doesn't matter as much if $V_{E}$ is allowed to change from generation to generation). From first principles, I think allowing heritability to change is probably the right choice. But, I've also set the model up so that you can run it either way, and we see if it makes a difference. Anecdotally, it doesn't seem to matter too much in the parameter spaces I've been exploring as I set up the model. 

At the end of all this, for each individual in each generation of the simulation, we have both their "breeding value" for the trait, and their actual phenotype for the trait. From these, we can calculate the heritability for the trait in that generation (which should be $\approx0.64$ when we're holding it constant, but can vary if we're not). We can use these phenotypes to estimate individual-level fitness (see next sections). 

Again, let's make some implicit assumptions of the model explicit. First, individuals can live multiple generations. The breeding values for a given individual won't change, but the environmental noise is added anew each generation, such that an individual's color phenotype could change year-to-year. This is maybe not biologically inaccurate: it seems possible that there could be some year-to-year plasticity in color (especially for a compound phenotype like the PC1 taken across of a bunch of spectrophotometry measures). But I'm not sure if we know that for sure? We can also look at the age structure to see how much of a possible issue this really is: from looking at some model metrics, most individuals aren't living for more than a year or two anyway, so there's isn't a ton of opportunity for individuals to have changning phenotypes anyway. Though it certainly could happen: even if most individuals are young, there is a long tail of older individuals. 

### Determining optimal phenotype

As we discussed, our GLMs that predict WTJR winter color based on environmental variables are basically maps of the "optimal" winter phenotype at a given location, given the snow and environmental variables. This relies on the (decent, but not ironclad) assumption that the phenotyped WTJR we used to create this model were well-adapted. Not sure there's anything we can do about that assumption.

Possibly more of an issue is the fact that this environment-to-phenotype modeling was done on binned binary phenotypes (white/brown) to create a continuous outcome, $Prob(brown)$. As reviewer three noted, there is some tension there, as it ignores the continuous color variation that is a big part of our story (and that is captured in the phenotypic PC score). I'm not fully sure how to resolve that. The tension becomes a little stronger when we have to relate our continuous $Prob(brown)$ variable to our continuous phenotypic PC to get some metric of environmental mismatch. For now, let's just make the assumption that these are more or less linearly related: individuals with high phenotypic PC scores (very brown) are most likely to be found in areas with high predicted $Prob(brown)$, very white individuals (low PC scores) are in areas with low $Prob(brown)$, and intermediate-colored individuals are most likely in areas with intermediate $Prob(brown)$. I know that assumption is arguable and was a point of contention between Scott and the Canadian hare folks RE: the 2018 Science paper (and we'd basically be taking the Canadian side), but at the moment I don't see an easy way around this if we want to use out predictive phenotype maps as some sort of metric of the optimum continuous phenotype. 

Conceptual tensions aside, we also need to reconcile the fact that these two metrics are on different numerical scales: $Prob(brown)$ ranges from 0 to 1 (both conceptually, and in our actual range-wide data), and the phenotypic PC ranges from -10 to 10 across all samples and from -6.48 to 3.66 in breeding values. In theory, it is easy to linearly rescale variables between ranges like this. If the min and max of the observed variables are $z_{min}$ and $z_{max}$, and we want the new scale to range from $scale_{min}$ to $scale_{max}$, than for a given value $z$ between $z_{min}$ and $z_{max}$ the scaled value is:

$z_{scaled} = \frac{z - z_{min}}{z_{max} - z_{min}} \cdot (scale_{max}- scale_{min}) + scale_{min}$

Once we rescale one of the variables, we have a simple measure of mismatch: the difference between $Prob(brown)$ and PC score when they're on the same scale. This makes the most sense when the PC scores are rescaled to the 0 to 1 interval to match the $Prob(brown)$ values. This has a nice mathematical property: the maximum possible phenotype-environment mismatch is 1 (or -1). E.g., a rescaled phenotype of 0 (the most white possible) in an environment with $Prob(brown) = 1$ would have a phenotype-environment mismatch of 1. This makes reasoning about selection strengths (the next section) a little easier.

Choosing observed min and max values for the PC scale is a bit of an issue. We could choose the absolute min and max observed in our dataset (-10 to 10), but that doesn't match well with the breeding values in our linear model: the maximum brown breeding value, 3.66, would only be 0.5 when re-scaled between -10 and 10, such that it would be very mismatched in a brown-favoring environment where $Prob(brown)$ = 1. Instead, I'm choosing the min and max of the breeding values. I'll note that, because of the $V_{E}$, individuals can actually have rescaled values outside of 0 and 1. This could be odd for measuring mismatch. E.g., an individual with the max breeding value of 3.66 and environmental noise that pushed their phenotype to 4 would get rescaled to 1.03. If the optimal value was $Prob(brown)$ = 1, that individual would actually be mismatched for being "too brown". So, for calculating mismatch, I set any rescaled phenotypes outside the 0 to 1 range back to 0 or 1. But, I do all the heritability calculations on the raw phenotype values (before rescaling), to avoid the issues that truncation would cause (underestimation of $V_{E}$, overestimation of heritability). 

### Selection on phenotype 

At this point, we have a genetic architecture, we're translated that into a phenotype, and compared that phenotype to a theoretical ideal phenotype to quantify phenotype-environment mismatch. So, the final step is to specify a fitness function that translates environmental mismatch into fitness. 

The Gaussian function seems like a good choice for this. This is the function that is used to describe a normal distribution, and has some nice properties for us (symmetric, provides both directional and stabilizing selection, minimal assumptions). It has three parameters we need to specify:

$f(x)=a\cdot\exp(-\frac{(x-b)^2}{2c^2})$

* $a$ is the height of the Gaussian function at its maximum (in the equation for the PDF of the normal distribution, this would be $\frac{1}{c\sqrt{2\pi}}$, to make sure the area under the curve integrates to 1). Here, we want $f(x)$ to represent fitness, and $x$ to represent mismatch. In the nonWF of SLiM, fitness equals the probability of survival. What should the max probability of survival be? Its important to note that in SLiM individual-level fitnesses are calculated first, and then all those fitnesses are scaled according to the population size and carrying capacity. I discuss the scaling below, but for now all that matters is that the scaling factor is 1 only when $N = K$. So, another way of thinking of $a$ is that it is the survival probability for a perfectly-matched individual when the population is exactly at the carrying capacity. After testing out various things, I think this needs to be 1. At first this maybe doesn't quite make intuitive sense: 100% survival probability seems unnatural. But, if the population is exactly at carrying capacity and all individuals are perfectly adapted (no mismatch), no individuals should be dying: the environment can support them all. Using a value < 1 basically implies a lower carrying capacity than $K$ (e.g., in playing with the simulations, if $a$ = 0.8 and $K$ = 5000, a perfectly-adapted population hovers around 4000 individuals, which is 80% of $K$). So we'll just keep this as 1, so our $K$ is meaningful. 

* $b$ is the $x$ value at which $f(x)$ is at its maximum. Picking $b$ is easy: we want fitness to be maximized at 0, when there is no mismatch.

* $c$ is the width of the Gaussian function, which determines how quickly fitness drops of when individuals are mismatched. Picking a value for this is a little tougher, as we don't really know how strong selection should be. The best we have to go on is Marketa's work with snowshoe hares. There, completely mismatched individuals had a 7% lower weekly survival rate. We assume above that annual survial for a perfectly matched hare in a population at carry capacity is 1. Weekly survival for such a hare would then also be 1. For a completely mismatched hare, this weekly survival should be 7% lower: 0.93. We then use that weekly survival rate to calculate the annual survival. This depends on how many weeks a hare can be mismatched. The areas we're most interested in simulating are those that are seeing some of the biggest changes in the $Prob(brown)$ across the range. This occurs in northwestern CO and northeastern UT. I picked out a representative point in that area that has a very large change in $Prob(brown)$, from 0.13 currently to 0.876 in the future. Currently, this location has ~16 weeks of snow cover, which we'll say is the time the hare could be mismatched. So, we can use that to estimate annual survival for completely mismatched hares: $0.93^{16}$, or 31.3% survival. So, we want to find a $c$ such that $f(1) = 0.31$. I used R's root solvers to figure that out: for 16 weeks $c$ = 0.6562. We can calculate $c$ for other winter lengths or for other fitness penalties. 

With $a$, $b$, and $c$ defined, we have our function that relates mismatch to individual survival probability. These individual survival probabilities will be scaled according to population-level regulatory forces (next section) before they are used to enact viability selection. 

Implicit assumptions made explicit: mismatch selection is symmetrical, such that brown-on-white mismatch has the same cost as white-on-brown mismatch. 

### Population regulation

For now, I'm doing simple density-dependent population regulation, with a carrying capacity, $K$, of 5000 individuals. We can change that to whatever carrying capacity makes sense for WTJR, if we have any good estimates based on population density or short-term effective population size. I assume the carrying capacity is constant through time. Each individual's fitness (call it $w_{i}$), which we calculated above using the Gaussian function, is scaled by a population-level constant determined by the carrying capacity and the current population size, $N$:

$w_{i}^{scaled} = w_{i}\cdot min(\frac{K}{N}, 1.2)$

So, when $N$ = $K$ individual fitnesses aren't changed, when $K$ > $N$ fitnesses are scaled up, and when $K$ < $N$ fitnesses are scaled down. Importantly, I impose a maximum benefit to low density: individual level fitnesses can never be increased by more than 20%, even when populations sizes are much smaller than $K$. This is necessary if the population is to have a possibility of declining and going extinct: otherwise, when population size gets really low, even very low-fitness can have their survival probability rescaled back up to 1. The 20% choice is arbitrary, we could discuss changing it. I have more discussion of the choice to impose a maximum benefit in the last section.  

### Change in optimal phenotype through time

I have the model set up so that one can specify the number of generations to simulate and also specify the initial optimal phenotype and the final optimal phenotype (both on the 0 to 1 scale). For simplicity's sake, the optimal phenotype changes linearly through time from the initial to the final optimal phenotype over the specified number of generations. Thus, we can simulate more- and less-severe climate change scenarios by varying both the amount of phenotypic change, and by varying the speed of that change and the number of generations over which individuals have time to adapt. 

## Preliminary results

So, the point of all this is to simulate how WTJR will adapt to changing climates. In particular, we're interested in understanding population dynamics in the areas with the greatest expected change in winter phenotype. These are areas that have relatively low $Prob(brown)$ now, but will have high $Prob(brown)$ in the future. These areas also, presumably, have relatively low frequencies of winter-brown alleles, such that they may not have the SGV to be able to adapt to rapidly changing environments. 

At this point, my preliminary results for this are mostly anecdotal. I have run many simulations under varying parameters and scenarios as I've worked out all these details. One parameter space I've been focusing on is our hypothetical UT/CO population, which will see a change of $Prob(brown)$ from 0.13 to 0.876. An important choice for this is the starting frequency of the brown alleles. One wrinkle is that according to Table S12, the frequency of the brown corin allele in white CO populations is surprisingly high. If I use those values to start the simulation, our hypothetical population actually starts off being maladapted for being too brown, not too white: the population declines, rebounds a bit as the optimal increases to the brown level it started at, then starts to decline again as the the optimal phenotype gets browner. I can pick lower starting allele frequencies, such that the population starts off with a phenotype closer to the initial optimum of 0.13. Either way, population declines are modest (10-15%), and they start to rebound pretty quickly.

We won't have the real answers until I can finalize the last few details and run a bunch of replicate simulations in a systematic way across a wide range of parameters. But, my initial guess is that the simulations will not play out the way were were expecting. From my initial simulations, it seems that populations may not be as vulnerable as we thought, and even populations with very low frequencies of the brown allele may be able to adapt to a big shift in optimal winter color. In short, from the simulations so far evolutionary rescue seems very plausible. Of course, this depends on there being some SGV of brown alleles present in the first place: if I set initial brown allele frequencies to 0, populations do decline severely (though they don't seem to go extinct within only 60 generations). 

These results are also somewhat unexpected given the results in the Kardos and Luikart simulation paper: that paper suggests that, heritability being equal, large-effect genetic architectures are more susceptible to loss/extinction than polygenic architectures. We're definitely on the large-effect genetic architecture, so we'd think these population might be more vulnerable, all things being equal. I'll have to think about and look into this more. Of course, all else may not be equal. In particular, I think the phenotypic shifts we're modeling may be less severe than they modeled. Spread out over 60 generations, even our hypothetical UT/CO population is changing only ~1% $Prob(brown)$ per year. Kardos and Luikart model an instantaneous change in the optimum of ~3 standard deviations of the trait. I'm not sure what the 1% $Prob(brown)$ is in terms of SDs of the color phenotype, but I expect that with the initial conditions (HW equilibirum, unlinked loci) the initial phenotypic variance could be rather large, such that the shift is actually mild in SD terms. 

## Other things I'd like to test or add

Some possibilites of things to add, based on suggestions from Jeff:

* One big feature of WTJR populations is that they cycle. This could be interesting to add in, as one could imagine that low points in the cycling would make the population more vulnerable. This would not be hard to simulate: I'd just allow $K$ to vary through time according to some function. The trick will be finding appropriate parameters for whatever cycking function we might want to use.

* Another possibility is to experiment a little with the differences in genetic architecture between WTJR and snowshoe hares, and discuss the conservation genetic implications of these differneces. The fact that winter coloration seems additive in WTJR, while winter white is dominant in SSH, could lead to some differences in susceptibility to change. This could add more evidence to the idea that knowing the genetic architecture of selected traits is important. 

## Some more nitty-gritty thoughts and explanations

I want to expand here on two of the modeling choices that ended up mattering a lot and that I did a lot of experimentation with: population-level regulation and offspring generation. 

In my testing, one scenario I tested frequently was simulating completely mismatched populations with no brown alleles (that is, initial and final optimal phenotypes of $Prob(brown)$ = 1, in populations with no brown alleles). These should go extinct. But, I couldn't get these populations to go extinct unless I made the fitness function extremely narrow, such that completely mismatched inddivudals had 0 fitness. With more reasonable values of $c$, like $c$ = 0.65, which give completely mismatched individuals a 30% chance of survival, I found that the population seems to have a minimum equilibrium at whatver was 30% of carrying capacity. After a lot of investigation, I figured out that this was due to issues with both population-level regulation and offspring generation.

First, for population-level regulation. Originally, I imposed no maximum benefit: the fitness scaling parameter was simply $\frac{K}{N}$. It turns out this scaling interacts badly with the way SLiM models fitness (as survival probability). E.g., with $K$ = 5000 and $N$ = 10 (only 10 individuals left), the population fitness scaling factor is 500. Even if those 10 individuals had, on average, a 1% survival chance BEFORE population scaling, they all have 100% chance of survival after (5000/10*0.01 = 5, which gets truncated to 100% survival probability). So, the low-density benefit was too strong, and kept populations from going extinct. I tried a few things, and eventually settled on the "maximum benefit" strategy I mention above.

In doing that testing, though, I found another issue preventing extinctions: very high reproductive output. Even when I completely took away any fitness benefits at low densities, populations wouldn't go extinct and would again hit a minimum equilibrium of ~30% of$K$. I had picked some plausible numbers from the literature for number of litters and size of litter, and those led, on average, to ~7 offspring per breeding pair. This number of offspring is high enough that the population can replenish itself from 30% of $K$ to $K$ within a single generation, even if you take away any density dependent scaling (that is, even if the survival rate for completely mismatched individuals does not get scaled up from 30%). After playing around with more numbers, I realized that there is a simple relationship between the average number of offspring per breeding pair that is necessary to fully replenish a given population to $K$ and the minimum survival rate of completely mismatched hares (call it $s$):

$\frac{2(1-s)}{s}$

This doesn't depend on the carrying capacity, only the survival rate in a completely maladapted population. So, given the modeled 30% minimum survival rate, the original reproductive output was too high: it needs to be below 4.67, or the population replenishes to $K$ or above. So, I fixed that by only allowing 1 to 3 offspring per litter, instead of 1 to 6, which brings the average number of offspring per pair to ~4.1-4.3, allowing populations to go extinct. If we change the width of the fitness function (and thus the survival rate of mismatched individuals), we may need to adjust reproductive output as well. 

```{r, eval = F}
expand_grid(corin = c(0,1,2), ednrb = c(0,1,2)) %>% 
  mutate(bv = -6.48 + 1.92*corin + 3.15*ednrb) %>% 
  mutate(scaled = (bv - -6.48)/(3.66 - -6.48)) %>% 
  arrange(bv)

```


